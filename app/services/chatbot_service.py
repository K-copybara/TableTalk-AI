import os
import ast
import logging
from typing import Optional, List, Dict, Any, TypedDict, Literal

# LangChain ë° LangGraph ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
from langchain_openai import ChatOpenAI
from langchain_core.tools import tool
from langchain_core.documents import Document
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain.prompts import ChatPromptTemplate
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from pydantic import BaseModel

# ì™¸ë¶€ ì„œë¹„ìŠ¤ ë° ì„¤ì •
from app.services.vectorstore_service import VectorStoreService, vectorstore_service
from app.core.config import settings

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- 1. ëŒ€í™” ê¸°ë¡(History) ê´€ë¦¬ ---
# ì„¸ì…˜ë³„ ëŒ€í™” ê¸°ë¡ì„ ì¸ë©”ëª¨ë¦¬ì— ì €ì¥í•©ë‹ˆë‹¤. ìš´ì˜ í™˜ê²½ì—ì„œëŠ” Redis ë“±ìœ¼ë¡œ êµì²´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
_session_histories = {}

def get_session_history(session_id: str) -> ChatMessageHistory:
    if session_id not in _session_histories:
        _session_histories[session_id] = ChatMessageHistory()
    return _session_histories[session_id]


# --- 2. LangGraph ìƒíƒœ ë° ì˜ë„ ì •ì˜ ---

class ChatState(TypedDict, total=False):
    """LangGraphì˜ ê° ë…¸ë“œë¥¼ ê±°ì¹˜ë©° ì „ë‹¬ë  ìƒíƒœ ê°ì²´"""
    input: str
    store_id: int
    chat_history: List[BaseMessage]
    intent: str
    params: Dict[str, Any]
    prev_params: Optional[Dict[str, Any]]
    excluded_allergens: List[str]
    required_allergens: List[str]
    result: Any
    docs: List[Any] #ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì„ì‹œ ì €ì¥

class Intent(BaseModel):
    """LLMì´ ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ ë¶„ë¥˜í•˜ê³  íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ì¶œí•˜ê¸° ìœ„í•œ Pydantic ëª¨ë¸"""
    kind: Literal[
        "add_to_cart", "send_request", "get_information", "allergy_filtering", 
        "get_store_info", "get_menu_detail"
    ]
    menu_name: Optional[str] = None
    quantity: Optional[int] = None
    query: Optional[str] = None
    max_price: Optional[int] = None
    is_popular: Optional[bool] = None
    user_allergy_request: Optional[str] = None
    allergy_mode: Optional[Literal["include", "exclude"]] = "exclude"
    excluded_menus: Optional[List[str]] = None
    request_message: Optional[str] = None


# --- 3. í•µì‹¬ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤ ---

class ChatbotService:
    """LangGraph ê¸°ë°˜ì˜ ì±—ë´‡ ë¡œì§ì„ ì´ê´„í•˜ëŠ” ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""

    def __init__(self, vs:VectorStoreService):

        self.vectorstore_service = vs
        self.llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

        self.find_menu_documents = tool(self._find_menu_documents)
        self.map_allergens_to_ingredients = tool(self._map_allergens_to_ingredients)
        self.add_to_cart = tool(self._add_to_cart)
        self.send_request_to_store = tool(self._send_request_to_store)
        self.get_store_info = tool(self._get_store_info)
        self.get_menu_detail = tool(self._get_menu_detail)

        # ë‚˜ì¤‘ì— agentì— ë…¸ì¶œí•˜ë ¤ë©´ ì´ ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©
        self.tools = [
            self.find_menu_documents,
            self.map_allergens_to_ingredients,
            self.add_to_cart,
            self.send_request_to_store,
            self.get_store_info,
            self.get_menu_detail,
        ]

        # --- LangGraph ì›Œí¬í”Œë¡œìš° ë¹Œë“œ ---
        workflow = StateGraph(ChatState)

        workflow.add_node("classify", self.classify_node)
        workflow.add_node("add_to_cart", self.add_to_cart_node)
        workflow.add_node("send_request", self.send_request_node)
        workflow.add_node("get_information", self.get_information_node)
        workflow.add_node("allergy_map", self.allergy_map_node)
        workflow.add_node("generate_response", self.generate_response_node)
        workflow.add_node("get_store_info", self.get_store_info_node)
        workflow.add_node("get_menu_detail", self.get_menu_detail_node)

        workflow.set_entry_point("classify")

        workflow.add_conditional_edges(
            "classify",
            self._route_from_classify,
            {
                "add_to_cart": "add_to_cart",
                "send_request": "send_request",
                "get_information": "get_information",
                "allergy_filtering": "allergy_map",
                "get_store_info": "get_store_info",
                "get_menu_detail": "get_menu_detail"
            }
        )

        workflow.add_edge("allergy_map", "get_information") # ì•Œë ˆë¥´ê¸° ë³€í™˜ í›„ì—ëŠ” í•­ìƒ ì¶”ì²œ ë…¸ë“œë¡œ ì´ë™
        workflow.add_edge("get_information", "generate_response")

        workflow.add_edge("add_to_cart", END)
        workflow.add_edge("send_request", END)
        workflow.add_edge("generate_response", END)
        workflow.add_edge("get_store_info", END)
        workflow.add_edge("get_menu_detail", END)

        checkpointer = MemorySaver()
        self.graph = workflow.compile(checkpointer=checkpointer)

        self.graph_with_history = RunnableWithMessageHistory(
            self.graph,
            get_session_history,
            input_messages_key="input",
            history_messages_key="chat_history",
            output_messages_key="result",
        )

    # --- ë„êµ¬(Tool) ì •ì˜ ---
    def _find_menu_documents(self,
        store_id: int, query: str, max_price: Optional[int] = None, 
        excluded_allergens: Optional[List[str]] = None, required_allergens: Optional[List[str]] = None,
        excluded_menus: Optional[List[str]] = None
    ):
        """ì‚¬ìš©ìì˜ ì¡°ê±´ì— ë§ëŠ” ë©”ë‰´ Document ë¦¬ìŠ¤íŠ¸ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰í•˜ì—¬ ë°˜í™˜"""
        filters = []
        if max_price is not None:
            filters.append({"price": {"$lte": max_price}})

        combined_filter = {"$and": filters} if filters else None
        print(f"ì‚¬ì „ í•„í„° ìƒì„± VectorDB í•„í„° ì¡°ê±´: {combined_filter}")

        candidate_docs = []
        search_query = query if query else "ë§›ìˆëŠ” ë©”ë‰´ ì¶”ì²œ"
        # ì¶”í›„ ì¸ê¸°ë„ ë°˜ì˜ ë¡œì§ í•„ìš”

        candidate_docs = self.vectorstore_service.search_menus(
            store_id=store_id,
            query=search_query,
            filter_dict=combined_filter,
            k=10
        )
        print(f"ğŸ“š [VectorDB ê²€ìƒ‰] ì¿¼ë¦¬: '{search_query}', í•„í„°: {combined_filter}")

        final_results = []
        required_allergens_set = set(required_allergens or [])
        excluded_allergens_set = set(excluded_allergens or [])
        excluded_menus_set = set(excluded_menus or [])

        print(f"âœ… í¬í•¨ ì¡°ê±´: {sorted(list(required_allergens_set))} / ğŸ™… ì œì™¸ ì¡°ê±´: {sorted(list(excluded_allergens_set))}")
        print(f"ğŸ™… ì´ë¦„ ì œì™¸ ì¡°ê±´: {sorted(list(excluded_menus_set))}")

        for doc in candidate_docs:
            menu_name = doc.metadata.get("menu_name", "")
            if any(keyword in menu_name for keyword in excluded_menus_set if keyword):
                continue

            allergens_str = doc.metadata.get("allergens", "")
            menu_allergens = {allergen.strip() for allergen in allergens_str.split(',')} if allergens_str else set()

            if required_allergens_set and not menu_allergens.intersection(required_allergens_set):
                continue

            if excluded_allergens_set and menu_allergens.intersection(excluded_allergens_set):
                continue

            final_results.append(doc)

        if not final_results:
            return [] 
        return final_results

    
    def _map_allergens_to_ingredients(self, store_id: int, user_allergy_request: str) -> List[str]:
        """ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ ìì—°ì–´ ì•Œë ˆë¥´ê¸° ìš”ì²­ì„ ì‹¤ì œ ì¬ë£Œ ëª©ë¡ìœ¼ë¡œ ë§¤í•‘"""
        available_allergens = self.vectorstore_service.get_all_allergens(store_id)
        prompt = (
            f"ì‚¬ìš©ì ì•Œë ˆë¥´ê¸° ìš”ì²­: \"{user_allergy_request}\"\n"
            f"ê°€ê²Œ ì•Œë ˆë¥´ê² ë¼ë²¨ ëª©ë¡: {available_allergens}\n\n"
            "ìœ„ ëª©ë¡ì— ì¡´ì¬í•˜ëŠ” ë¼ë²¨ë§Œ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ ì•Œë ˆë¥´ê²ì„ íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•˜ì„¸ìš”.\n"
            "ì˜¤ì§ ë¦¬ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•˜ì„¸ìš”. ì˜ˆ: ['ëŒ€ë‘','ë•…ì½©']"
        )
        #ì¶”í›„ JSON + json.loadsë¡œ ì•ˆì •í™” í•„ìš”

        print(f"ğŸ§  [LLM í˜¸ì¶œ] ì•Œë ˆë¥´ê² ë³€í™˜: '{user_allergy_request}' -> ? (ëŒ€ìƒ: {available_allergens})")
        response = self.llm.invoke(prompt)
        llm_output = response.content.strip() # type: ignore
        print(f"ğŸ§  [LLM ì‘ë‹µ] ì•Œë ˆë¥´ê² ë³€í™˜: '{user_allergy_request}' -> {llm_output}")

        try:
            ingredients = ast.literal_eval(llm_output)

            if isinstance(ingredients, list):
                return ingredients
            else:
                print(f"âš ï¸ [íŒŒì‹± ê²½ê³ ] LLM ì‘ë‹µì´ ë¦¬ìŠ¤íŠ¸ í˜•íƒœê°€ ì•„ë‹™ë‹ˆë‹¤: {llm_output}")
                return []
        except (SyntaxError, ValueError) as e:
            # LLM ì‘ë‹µì´ íŒŒì‹± ë¶ˆê°€ëŠ¥í•œ í˜•íƒœì¼ ê²½ìš° (ì˜ˆ: "['ë•…ì½©', 'ì£'")
            logger.info(f"ğŸš¨ [íŒŒì‹± ì˜¤ë¥˜] LLM ì‘ë‹µì„ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {llm_output}, ì˜¤ë¥˜: {e}")
            return []

    def _add_to_cart(self, store_id: int, menu_name: str, quantity: int):
        """ì‚¬ìš©ìê°€ ë§í•œ ë©”ë‰´ ì´ë¦„ì„ ê¸°ë°˜ìœ¼ë¡œ IDë¥¼ ì°¾ê³ , ì¥ë°”êµ¬ë‹ˆì— ì¶”ê°€í•˜ëŠ” ëª¨ë“  ê³¼ì •ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        print(f"ğŸ“š [VectorDB ì¡°íšŒ] ë©”ë‰´ ID ê²€ìƒ‰ -> ê°€ê²Œ id: {store_id}, ì´ë¦„: '{menu_name}'")

        docs = self.vectorstore_service.find_document(
                query=menu_name,
                store_id=store_id,
                type="menu"
            )

        if docs:
            menu_name = docs[0].metadata.get("menu_name")
            menu_id = docs[0].metadata.get("menu_id")

            if menu_id is not None:
                logger.info(f"ğŸ” [ê²€ìƒ‰ ê²°ê³¼] '{menu_name}'ì˜ IDëŠ” {menu_id} ì…ë‹ˆë‹¤.")
                logger.info(f"âœ… [API í˜¸ì¶œ] ì•„ì´ë””: {menu_id}, ìˆ˜ëŸ‰: {quantity} -> ì¥ë°”êµ¬ë‹ˆ ì¶”ê°€")
                # ì‹¤ì œ ë°±ì—”ë“œ API í˜¸ì¶œ ë¡œì§
                return f"'{menu_name}' {quantity}ê°œë¥¼ ì¥ë°”êµ¬ë‹ˆì— ì„±ê³µì ìœ¼ë¡œ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤."

        logger.info(f"âš ï¸ [ê²€ìƒ‰ ì‹¤íŒ¨] '{menu_name}' ë©”ë‰´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return f"'{menu_name}'ì´ë¼ëŠ” ë©”ë‰´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë©”ë‰´ ì´ë¦„ì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”."

    def _send_request_to_store(self, request_message: str):
        """ë¬¼í‹°ìŠˆ, ì•ì¹˜ë§ˆ ë“± ê³ ê°ì˜ ìš”ì²­ì‚¬í•­ì„ ê°€ê²Œì— ì „ë‹¬í•©ë‹ˆë‹¤."""
        logger.info(f"âœ… [API í˜¸ì¶œ] ìš”ì²­ì‚¬í•­: '{request_message}' -> ê°€ê²Œ ì „ë‹¬")
        return f"'{request_message}' ìš”ì²­ì„ ê°€ê²Œì— ì „ë‹¬í–ˆìŠµë‹ˆë‹¤."

    def _get_store_info(self, store_id: int) -> str:
        """ê°€ê²Œ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."""
        docs = self.vectorstore_service.find_document(
                query="ê°€ê²Œ ì •ë³´",
                store_id=store_id,
                type="store_info"
            )
        if docs:
            content = docs[0].page_content
            print(f"ê°€ê²Œ ì •ë³´: {content}")
            return content

        return ""
    
    def _get_menu_detail(self, store_id: int, menu_name: str) -> str:
        """ë©”ë‰´ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."""
        docs = self.vectorstore_service.find_document(
                query=menu_name,
                store_id=store_id,
                type="menu",
                k=5
            )
        if docs:
            content = docs[0].page_content
            print(f"ë©”ë‰´ ì •ë³´: {content}")
            return content

        return ""
    

        

    # --- LangGraph ë…¸ë“œ í•¨ìˆ˜ (í´ë˜ìŠ¤ ë©”ì„œë“œë¡œ ë³€í™˜) ---

    def classify_node(self, state: ChatState) -> Dict[str, Any]:
        """LLMì„ ì‚¬ìš©í•´ ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ ë¶„ë¥˜í•˜ê³  íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ì¶œ"""
        hist = self._render_history(state.get("chat_history", []))
        prev_params = state.get("prev_params")

        system = (
            "ë‹¹ì‹ ì€ ìŒì‹ì  ê³ ê°ì‘ëŒ€ ë³´ì¡°ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìš”ì²­ ì˜ë„ë¥¼ ì•„ë˜ 5ì¢… ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.\n"
            "- add_to_cart: ì¥ë°”êµ¬ë‹ˆì— ë©”ë‰´ ì¶”ê°€\n"
            "- send_request: ê°€ê²Œì— ëŒ€í•œ ìš”ì²­ì‚¬í•­ ì „ë‹¬\n"
            "- get_information: íŠ¹ì • ì¡°ê±´(ê°€ê²©, ì¸ê¸°, ì¶”ê°€ ë¬˜ì‚¬ ë“±)ì— ë§ëŠ” ë©”ë‰´ ì¶”ì²œ\n"
            "- allergy_filtering: íŠ¹ì • ì¬ë£Œì˜ í¬í•¨/ë¯¸í¬í•¨ ì—¬ë¶€ë¡œ ë©”ë‰´ ì •ë³´ ìš”ì²­\n"
            "- get_store_info: ê°€ê²Œì˜ ì´ë¦„, ì„¤ëª…, ì˜ì—…ì‹œê°„, ë¸Œë ˆì´í¬íƒ€ì„ ë“± ê°€ê²Œì— ëŒ€í•œ ì •ë³´ ìš”ì²­\n"
            "- get_menu_detail: íŠ¹ì • ë©”ë‰´ì˜ ê°€ê²©/ë§µê¸°/ì•Œë ˆë¥´ê²/ì„¤ëª…ì— ëŒ€í•œ ìš”ì²­\n"
            "ì•Œë ˆë¥´ê¸° ë¶„ë¥˜ ê·œì¹™:\n"
            "- ì‚¬ìš©ìê°€ ì¬ë£Œê°€ **'ë“¤ì–´ê°„', 'í¬í•¨ëœ'** ë©”ë‰´ë¥¼ ì°¾ìœ¼ë©´, `kind`ëŠ” 'allergy_filtering'ë¡œ, `allergy_mode`ëŠ” 'include'ë¡œ ì„¤ì •í•˜ì„¸ìš”.\n"
            "- ì‚¬ìš©ìê°€ ì¬ë£Œê°€ **'ì—†ëŠ”', 'ì•ˆ ë“¤ì–´ê°„', 'ëº€'** ë©”ë‰´ë¥¼ ì°¾ìœ¼ë©´, `kind`ëŠ” 'allergy_filtering'ë¡œ, `allergy_mode`ëŠ” 'exclude'ë¡œ ì„¤ì •í•˜ì„¸ìš”.\n\n"
            "**ì˜ˆì‹œ:**\n"
            "- ì‚¬ìš©ì ì…ë ¥: 'ì½© ë“¤ì–´ê°„ ë©”ë‰´ ë­ìˆì–´?' -> kind: 'allergy_filtering', user_allergy_request: 'ì½©', allergy_mode: 'include'\n"
            "- ì‚¬ìš©ì ì…ë ¥: 'ì½© ì•ˆë“¤ì–´ê°„ ë©”ë‰´ ì¶”ì²œí•´ì¤˜' -> kind: 'allergy_filtering', user_allergy_request: 'ì½©', allergy_mode: 'exclude'"
            "ì‚¬ìš©ìê°€ 'ê·¸ê±°', 'ì €ê±°', 'ì²«ë²ˆì§¸êº¼', 'ë§ˆì§€ë§‰ ë©”ë‰´' ë“± ëŒ€ëª…ì‚¬ë‚˜ ì§€ì‹œì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ìš”ì²­í•  ê²½ìš°, ë°˜ë“œì‹œ 'chat_history'ë¥¼ ì°¸ê³ í•˜ì—¬ ê·¸ê²ƒì´ ì–´ë–¤ íŠ¹ì • ë©”ë‰´ë¥¼ ì§€ì¹­í•˜ëŠ”ì§€ ëª…í™•íˆ íŒŒì•…í•´ì•¼ í•©ë‹ˆë‹¤."
            "ì¡°ê±´ ì„¤ì • ê·œì¹™:\n"
            "1. ìƒˆë¡œìš´ ìš”ì²­ì´ ì´ì „ ì¡°ê±´ê³¼ ì—°ê´€ì´ ì—†ë‹¤ë©´, ì´ì „ ì¡°ê±´ì„ ì™„ì „íˆ ë¬´ì‹œí•˜ê³  ìƒˆë¡œìš´ ì¡°ê±´ë§Œ ìƒì„±í•˜ì„¸ìš”.\n"
            "2. ìƒˆë¡œìš´ ìš”ì²­ì´ ì´ì „ ì¡°ê±´ì„ ìˆ˜ì •í•˜ê±°ë‚˜ ì¶”ê°€í•˜ëŠ” ê²ƒì´ë¼ë©´, ì´ì „ ì¡°ê±´ì„ ê³„ìŠ¹í•˜ì—¬ ë³€ê²½ëœ ë¶€ë¶„ë§Œ ë°˜ì˜í•˜ì„¸ìš”.\n"
            "3. ë©”ë‰´ ì¶”ì²œ í›„ ì‚¬ìš©ìê°€ 'ê·¸ê±° ë§ê³ ', 'ë‹¤ë¥¸ ê±°', '~ ë¹¼ê³ ', '~ ì œì™¸í•˜ê³ ' ë“±ì˜ í‘œí˜„ìœ¼ë¡œ ê°™ì€ ì¡°ê±´ìœ¼ë¡œ ë‹¤ì‹œ ì¶”ì²œì„ ìš”ì²­í•œë‹¤ë©´,"
            "`chat_history`ì—ì„œ ì´ì „ì— ì¶”ì²œí–ˆë˜ ë©”ë‰´ ì´ë¦„ì„ ì •í™•íˆ ì°¾ì•„ë‚´ `excluded_menus` ë¦¬ìŠ¤íŠ¸ì— ë‹´ì•„ì£¼ì„¸ìš”.\n"
            "4. ì‚¬ìš©ìì˜ ìš”ì²­ì´ ëª¨í˜¸í•˜ë©´ `chat_history`ë¥¼ ì°¸ê³ í•˜ì—¬ ì˜ë„ë¥¼ ëª…í™•íˆ í•˜ì„¸ìš”.\n\n"
            "--- ì˜ˆì‹œ ---\n"
            "- ì´ì „ ì¡°ê±´: {'query': 'ì•ˆ ë§¤ìš´ ë©”ë‰´'}\n"
            "- ìƒˆë¡œìš´ ìš”ì²­: 'ê·¸ëŸ¼ 10000ì› ì´í•˜ì¸ ê±¸ë¡œ ì°¾ì•„ì¤˜'\n"
            "- ê°±ì‹ ëœ ìµœì¢… ì¡°ê±´ -> {'query': 'ì•ˆ ë§¤ìš´ ë©”ë‰´', 'max_price': 10000}\n\n"
            "í•„ìš”í•œ ëª¨ë“  íŒŒë¼ë¯¸í„°ëŠ” JSONìœ¼ë¡œ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤."
        )
        print(f"ğŸ¤– ì˜ë„ ë¶„ë¥˜ ì‹œë„")
        classifier = self.llm.with_structured_output(Intent, method="function_calling")
        intent: Intent = classifier.invoke([
                {"role": "system", "content": system},
                {"role": "system", "content": f"ì´ì „ ì¡°ê±´: {prev_params if prev_params else 'ì—†ìŒ'}"},
                {"role": "system", "content":f"chat_history:\n{hist}"},
                {"role": "user", "content": state['input']}
            ])
        print(f"ğŸ¤– ë¶„ë¥˜ëœ ì˜ë„: {intent.kind}")
        print(f"âš™ï¸ ì¶”ì¶œëœ íŒŒë¼ë¯¸í„°: {intent.model_dump(exclude_none=True)}")

        params = intent.model_dump(exclude_none=True)
        if "query" not in params or not params["query"]:
            params["query"] = state.get("input", "").strip()

        return{
            "intent" : intent.kind,
            "params" : intent.model_dump(exclude_none=True),
        }
    
    def add_to_cart_node(self, state: ChatState) -> Dict[str, Any]:
        print("--- 3. ì¥ë°”êµ¬ë‹ˆ ì¶”ê°€ (ADD TO CART) ---")
        p = state["params"]
        quantity = p.get("quantity", 1)

        names: List[str] = []
        if p.get("menu_name"):
            names = [p["menu_name"]]
        else:
            prev_docs = state.get("docs")
            if isinstance(prev_docs, list):
                names = [
                    d.metadata.get("menu_name")
                    for d in prev_docs
                    if isinstance(d, Document) and d.metadata.get("menu_name")
                ]

        if not names:
                return {
                    "result": "ì–´ë–¤ ë©”ë‰´ë¥¼ ë‹´ì„ì§€ ëª…í™•í•˜ê²Œ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”? ğŸ˜Š"
                }

        msgs = []
        for name in names:
                res = self.add_to_cart.invoke({
                    "store_id": state["store_id"],
                    "menu_name": name,
                    "quantity": quantity
                })
                msgs.append(res)

        return {"result": "\n".join(msgs)}

    def send_request_node(self, state: ChatState) -> Dict[str, Any]:
        print("--- 4. ìš”ì²­ ì „ë‹¬ (SEND REQUEST) ---")
        msg = state["params"].get("request_message") or state["input"]
        result = self.send_request_to_store.invoke({"request_message": msg})
        return {"result": result}
    
    def generate_response_node(self, state: ChatState) -> Dict[str,Any]:
        """ê²€ìƒ‰ëœ ì •ë³´ì™€ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ ì§€ì •ëœ í˜•ì‹ì— ë§ì¶° ìµœì¢… ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        print("--- ìµœì¢… ë‹µë³€ ìƒì„± (GENERATE) ---")

        retrieved_docs = state["result"]
        params = state.get("params",{})

        if not retrieved_docs:
            return {"result": "ì•„ì‰½ì§€ë§Œ í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” ë©”ë‰´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì¡°ê±´ìœ¼ë¡œ ì§ˆë¬¸í•´ì£¼ì‹œê² ì–´ìš”?"}

        info_text = retrieved_docs[0].page_content

        query = state["input"]

        prompt = f"""ë‹¹ì‹ ì€ ê³ ê°ì—ê²Œ ë©”ë‰´ë¥¼ ì•ˆë‚´í•˜ëŠ” ì¹œì ˆí•œ ìŒì‹ì  ì ì›ì…ë‹ˆë‹¤.
            ì•„ë˜ 'ê²€ìƒ‰ëœ ì •ë³´'ë¥¼ ë°”íƒ•ìœ¼ë¡œ [ì¶œë ¥ í˜•ì‹]ì„ ì¤€ìˆ˜í•˜ë˜, ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ìƒì„±í•˜ì„¸ìš”.
            'ì•Œë ˆë¥´ê¸°ë¥¼ ìœ ë°œí•  ìˆ˜ ìˆëŠ” ì¬ë£Œ'ëŠ” ì§ˆë¬¸ê³¼ ê´€ë ¨ìˆëŠ” ê²½ìš°ì—ë§Œ ë‹µë³€ì— í¬í•¨í•˜ì„¸ìš”.

            [ì‚¬ìš©ìì˜ ì§ˆë¬¸]
            {query}

            [ê²€ìƒ‰ëœ ë©”ë‰´ ì •ë³´]
            {info_text}

            [ì¶œë ¥ í˜•ì‹]
            {{ì§ˆë¬¸ ì¡°ê±´}}ì— í•´ë‹¹í•˜ëŠ” ë©”ë‰´ëŠ” {{ë©”ë‰´ ì´ë¦„}}ì´(ê°€) ìˆìŠµë‹ˆë‹¤!
            ê°€ê²©ì€ {{ê°€ê²©}}ì›ì´ë©°, {{ë©”ë‰´ ì„¤ëª…}}.

            ---
            (ë§Œì•½ ì¶”ì²œí•  ë©”ë‰´ê°€ ì—¬ëŸ¬ ê°œë¼ë©´ ìœ„ í˜•ì‹ì„ ë°˜ë³µí•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.)
            ---

            [ë‹µë³€]
            """

        response = self.llm.invoke(prompt)
        return {"result": response.content}
    
    def get_information_node(self, state: ChatState) -> Dict[str, Any]:
        print("--- 5. ì •ë³´ ê²€ìƒ‰ (get_information) ---")
        p = state["params"]

        raw_query = p.get("query")
        user_text = state.get("input", "")
        query = (raw_query or user_text or "ë©”ë‰´ ì¶”ì²œ").strip()

        res = self.find_menu_documents.invoke({
                "store_id":state["store_id"],
                "query":query,
                "max_price":p.get("max_price"),
                "is_popular":p.get("is_popular", False),
                "excluded_allergens":state.get("excluded_allergens"),
                "required_allergens":state.get("required_allergens"),
                "excluded_menus": p.get("excluded_menus")
            })
        return {"result": res, "docs": res}
    
    def allergy_map_node(self, state: ChatState) -> Dict[str, Any]:
        print("--- 6. ì•Œë ˆë¥´ê¸° ë³€í™˜ (ALLERGY MAP) ---")
        p = state["params"]
        user_req = p.get("user_allergy_request") or state["input"]
        mode = p.get("allergy_mode", "exclude")

        mapped = self.map_allergens_to_ingredients.invoke({
                "store_id": state["store_id"],
                "user_allergy_request": user_req
            })

        if mode == "include":
            return {"required_allergens": mapped}
        else:
            return {"excluded_allergens": mapped}
        
    def get_store_info_node(self, state: ChatState) -> Dict[str,Any]:
        query = state["input"]
        print("ì‚¬ìš©ì ì§ˆë¬¸: ", query)
        store_info = self.get_store_info.invoke({"store_id": state["store_id"]})

        prompt = f"""ë‹¹ì‹ ì€ ê³ ê°ì—ê²Œ ê°€ê²Œ ì •ë³´ë¥¼ ì•ˆë‚´í•˜ëŠ” ì¹œì ˆí•œ ìŒì‹ì  ì ì›ì…ë‹ˆë‹¤.
            ì•„ë˜ 'ê°€ê²Œ ì •ë³´'ì—ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— í•´ë‹¹í•˜ëŠ” ì •ë³´ë¥¼ ì°¾ì•„ ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”.
            ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ì—†ëŠ” ì •ë³´ëŠ” ë‹µë³€ì— í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
            ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° 'ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.'ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.

            [ê°€ê²Œ ì •ë³´]
            {store_info}

            [ì‚¬ìš©ìì˜ ì§ˆë¬¸]
            {query}

            [ë‹µë³€]
            """

        response = self.llm.invoke(prompt)
        return {"result": response.content}

    def get_menu_detail_node(self, state: ChatState) -> Dict[str,Any]:
        query = state["input"]
        print("ì‚¬ìš©ì ì§ˆë¬¸: ", query)

        menu_name = state["params"].get("menu_name")
        if not menu_name and isinstance(state.get("docs"), list):
                # ì§ì „ ê²°ê³¼ì—ì„œ menu_name ì¶”ì¶œ
                for d in state["docs"]:
                    if d.metadata.get("menu_name"):
                        menu_name = d.metadata["menu_name"]
                        break

        if not menu_name:
            return {"result": "ì–´ë–¤ ë©”ë‰´ë¥¼ ë§ì”€í•˜ì‹œëŠ”ì§€ ë‹¤ì‹œ í•œ ë²ˆ ì•Œë ¤ì£¼ì„¸ìš”."}
        menu_detail = self.get_menu_detail.invoke({"store_id": state["store_id"], "menu_name":menu_name})

        prompt = f"""ë‹¹ì‹ ì€ ê³ ê°ì—ê²Œ ë©”ë‰´ ì •ë³´ë¥¼ ì•ˆë‚´í•˜ëŠ” ì¹œì ˆí•œ ìŒì‹ì  ì ì›ì…ë‹ˆë‹¤.
            ì•„ë˜ 'ë©”ë‰´ ì •ë³´'ì—ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— í•´ë‹¹í•˜ëŠ” ì •ë³´ë¥¼ ì°¾ì•„ ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”.
            ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ì—†ëŠ” ì •ë³´ëŠ” ë‹µë³€ì— í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
            ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° 'ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.'ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.
            'ì•Œë ˆë¥´ê¸° ìœ ë°œ ì¬ë£Œ'ëŠ” íŠ¹ì • ì¬ë£Œì— ëŒ€í•´ ë¬»ëŠ” ì§ˆë¬¸ì¸ ê²½ìš°ì—ë§Œ í™œìš©í•˜ì„¸ìš”.

            [ë©”ë‰´ ì •ë³´]
            {menu_detail}

            [ì‚¬ìš©ìì˜ ì§ˆë¬¸]
            {query}

            [ë‹µë³€]
            """

        response = self.llm.invoke(prompt)
        return {"result": response.content}

    def _route_from_classify(self, state: ChatState):
        return state["intent"]
    
    def _render_history(self, messages: List[BaseMessage], k: int = 6) -> str:
        simple = []
        for m in messages[-k:]:
            role = getattr(m, "type", getattr(m, "role", "user"))
            content = getattr(m, "content", "")
            simple.append(f"{role}: {content}")
        return "\n".join(simple)
    
    # --- Public ë©”ì„œë“œ ---

    def process_chat(self, session_id: str, user_input: str, store_id: int) -> str:
        """
        ì‚¬ìš©ì ì…ë ¥ì„ ë°›ì•„ ì „ì²´ ì±—ë´‡ í”Œë¡œìš°ë¥¼ ì‹¤í–‰í•˜ê³  ìµœì¢… ë‹µë³€ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        # LangGraph ì‹¤í–‰ì— í•„ìš”í•œ ì´ˆê¸° ìƒíƒœê°’ ì„¤ì •
        current_state = self.graph.get_state(config={"configurable": {"thread_id": session_id, "session_id": session_id}})
        prev_params = current_state.values.get("params") if current_state else None
        
        state = {"input": user_input, "store_id": store_id, "prev_params": prev_params}
        
        # ëŒ€í™” ê¸°ë¡ì´ í¬í•¨ëœ ê·¸ë˜í”„ ì‹¤í–‰
        output = self.graph_with_history.invoke(
            state,
            config={"configurable": {
            "thread_id": session_id,  # LangGraphì˜ ìƒíƒœ(state) ì €ì¥ìš©
            "session_id": session_id   # RunnableWithMessageHistoryì˜ ëŒ€í™” ê¸°ë¡ ì €ì¥ìš©
        }}
        )
        return output.get("result", "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

chatbot_service = ChatbotService(vs=vectorstore_service)